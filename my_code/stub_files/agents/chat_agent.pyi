import threading
from _typeshed import Incomplete
from camel.agents.base import BaseAgent
from camel.memories import AgentMemory
from camel.messages import BaseMessage, OpenAIMessage
from camel.models import BaseModelBackend
from camel.responses import ChatAgentResponse
from camel.terminators import ResponseTerminator as ResponseTerminator
from camel.toolkits import FunctionTool as FunctionTool
from camel.types import ModelPlatformType, ModelType, OpenAIBackendRole, RoleType
from pydantic import BaseModel as BaseModel
from typing import Any, Callable

logger: Incomplete
SIMPLE_FORMAT_PROMPT: Incomplete

class ChatAgent(BaseAgent):
    model_backend: Incomplete
    model_type: Incomplete
    agent_id: Incomplete
    memory: AgentMemory
    role_name: str
    role_type: RoleType
    terminated: bool
    response_terminators: Incomplete
    single_iteration: Incomplete
    stop_event: Incomplete
    def __init__(self, system_message: BaseMessage | str | None = None, model: BaseModelBackend | tuple[str, str] | str | ModelType | tuple[ModelPlatformType, ModelType] | list[BaseModelBackend] | list[str] | list[ModelType] | list[tuple[str, str]] | list[tuple[ModelPlatformType, ModelType]] | None = None, memory: AgentMemory | None = None, message_window_size: int | None = None, token_limit: int | None = None, output_language: str | None = None, tools: list[FunctionTool | Callable] | None = None, external_tools: list[FunctionTool | Callable | dict[str, Any]] | None = None, response_terminators: list[ResponseTerminator] | None = None, scheduling_strategy: str = 'round_robin', single_iteration: bool = False, agent_id: str | None = None, stop_event: threading.Event | None = None) -> None: ...
    def reset(self) -> None: ...
    @property
    def system_message(self) -> BaseMessage | None: ...
    @property
    def tool_dict(self) -> dict[str, FunctionTool]: ...
    @property
    def output_language(self) -> str | None: ...
    @output_language.setter
    def output_language(self, value: str) -> None: ...
    def add_tool(self, tool: FunctionTool | Callable) -> None: ...
    def add_external_tool(self, tool: FunctionTool | Callable | dict[str, Any]) -> None: ...
    def remove_tool(self, tool_name: str) -> bool: ...
    def remove_external_tool(self, tool_name: str) -> bool: ...
    def update_memory(self, message: BaseMessage, role: OpenAIBackendRole, timestamp: float | None = None) -> None: ...
    def load_memory(self, memory: AgentMemory) -> None: ...
    def load_memory_from_path(self, path: str) -> None: ...
    def save_memory(self, path: str) -> None: ...
    def clear_memory(self) -> None: ...
    def init_messages(self) -> None: ...
    def record_message(self, message: BaseMessage) -> None: ...
    def step(self, input_message: BaseMessage | str, response_format: type[BaseModel] | None = None) -> ChatAgentResponse: ...
    @property
    def chat_history(self) -> list[OpenAIMessage]: ...
    async def astep(self, input_message: BaseMessage | str, response_format: type[BaseModel] | None = None) -> ChatAgentResponse: ...
    def get_usage_dict(self, output_messages: list[BaseMessage], prompt_tokens: int) -> dict[str, int]: ...
    def add_model_scheduling_strategy(self, name: str, strategy_fn: Callable): ...
